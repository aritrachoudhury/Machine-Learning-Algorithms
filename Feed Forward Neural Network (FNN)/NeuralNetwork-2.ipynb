{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gL5YfHPGOUJQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def fit_NeuralNetwork(X_train,y_train,alpha,hidden_layer_sizes,epochs):\n",
        "    #Enter implementation here\n",
        "\n",
        "    # Initialize the epoch errors\n",
        "    err=np.zeros((epochs,1))\n",
        "\n",
        "    # Initialize the architecture\n",
        "    N, d = X_train.shape\n",
        "    X0 = np.ones((N,1))\n",
        "    X_train = np.hstack((X0,X_train))\n",
        "    d=d+1\n",
        "    L = len(hidden_layer_sizes)\n",
        "    L=L+2\n",
        "\n",
        "    #Initializing the weights for input layer\n",
        "    weight_layer = np.random.normal(0, 0.1, (d,hidden_layer_sizes[0])) #np.ones((d,hidden_layer_sizes[0]))\n",
        "    weights = []\n",
        "    weights.append(weight_layer) #append(0.1*weight_layer)\n",
        "\n",
        "    #Initializing the weights for hidden layers\n",
        "    for l in range(L-3):\n",
        "        weight_layer = np.random.normal(0, 0.1, (hidden_layer_sizes[l]+1,hidden_layer_sizes[l+1]))\n",
        "        weights.append(weight_layer)\n",
        "\n",
        "    #Initializing the weights for output layers\n",
        "    weight_layer= np.random.normal(0, 0.1, (hidden_layer_sizes[l+1]+1,1))\n",
        "    weights.append(weight_layer)\n",
        "\n",
        "    for e in range(epochs):\n",
        "        choiceArray=np.arange(0, N)\n",
        "        np.random.shuffle(choiceArray)\n",
        "        errN=0\n",
        "        for n in range(N):\n",
        "            index=choiceArray[n]\n",
        "            x=np.transpose(X_train[index])\n",
        "            #TODO: Model Update: Forward Propagation, Backpropagation\n",
        "            # update the weight and calculate the error\n",
        "             # Forward propagation\n",
        "            X, S = forwardPropagation(x, weights)\n",
        "\n",
        "            # Compute error per sample\n",
        "            eN = errorPerSample(X, y_train[index])\n",
        "            errN += eN\n",
        "\n",
        "            # Backpropagation to get gradients\n",
        "            g = backPropagation(X, y_train[index], S, weights)\n",
        "\n",
        "            # Update weights\n",
        "            weights = updateWeights(weights, g, alpha)\n",
        "\n",
        "        err[e]=errN/N\n",
        "    return err, weights\n",
        "\n",
        "def forwardPropagation(x, weights):\n",
        "    #Enter implementation here\n",
        "    l=len(weights)+1\n",
        "    currX = x\n",
        "    retS=[]\n",
        "    retX=[]\n",
        "    retX.append(currX)\n",
        "\n",
        "    # Forward Propagate for each layer\n",
        "    for i in range(l-1):\n",
        "\n",
        "        currS= np.dot(currX, weights[i])\n",
        "        #TODO: Dot product between the layer and the weight matrix\n",
        "        retS.append(currS)\n",
        "        currX=currS\n",
        "        if i != len(weights)-1:\n",
        "            for j in range(len(currS)):\n",
        "                currX[j]= activation(currS[j])\n",
        "        # TODO: Apply the activation\n",
        "            currX= np.hstack((1,currX))\n",
        "        else:\n",
        "            currX= outputf(currS)\n",
        "        #TODO: Apply the output activation\n",
        "        retX.append(currX)\n",
        "    return retX,retS\n",
        "\n",
        "def errorPerSample(X,y_n):\n",
        "    #Enter implementation here\n",
        "    # The last layer's output is the last element in X\n",
        "    x_L = X[-1]\n",
        "    # Calculate the error using the error function implemented in Part 1\n",
        "    eN = errorf(x_L, y_n)\n",
        "    return eN\n",
        "\n",
        "def backPropagation(X,y_n,s,weights):\n",
        "    #Enter implementation here\n",
        "    #x:0,1,...,L\n",
        "    #S:1,...,L\n",
        "    #weights: 1,...,L\n",
        "    l=len(X)\n",
        "    delL=[]\n",
        "\n",
        "    # To be able to complete this function, you need to understand this line below\n",
        "    # In this line, we are computing the derivative of the Loss function w.r.t the\n",
        "    # output layer (without activation). This is dL/dS[l-2]\n",
        "    # By chain rule, dL/dS[l-2] = dL/dy * dy/dS[l-2] . Now dL/dy is the derivative Error and\n",
        "    # dy/dS[l-2]  is the derivative output.\n",
        "    delL.insert(0,derivativeError(X[l-1],y_n)*derivativeOutput(s[l-2]))\n",
        "    curr=0\n",
        "\n",
        "    # Now, let's calculate dL/dS[l-2], dL/dS[l-3],...\n",
        "    for i in range(len(X)-2, 0, -1): #L-1,...,0\n",
        "        delNextLayer=delL[curr]\n",
        "        WeightsNextLayer=weights[i]\n",
        "        sCurrLayer=s[i-1]\n",
        "\n",
        "        #Init this to 0s vector\n",
        "        delN=np.zeros((len(s[i-1]),1))\n",
        "\n",
        "        #Now we calculate the gradient backward\n",
        "        #Remember: dL/dS[i] = dL/dS[i+1] * W(which W???) * activation\n",
        "        for j in range(len(s[i-1])): #number of nodes in layer i - 1\n",
        "            for k in range(len(s[i])): #number of nodes in layer i\n",
        "                #TODO: calculate delta at node j\n",
        "                delN[j]=delN[j]+ delNextLayer[k] * WeightsNextLayer[j, k] * derivativeActivation(sCurrLayer[j])\n",
        "                # Fill in the rest\n",
        "\n",
        "        delL.insert(0,delN)\n",
        "\n",
        "    # We have all the deltas we need. Now, we need to find dL/dW.\n",
        "    # It's very simple now, dL/dW = dL/dS * dS/dW = dL/dS * X\n",
        "    g=[]\n",
        "    for i in range(len(delL)):\n",
        "        rows,cols=weights[i].shape\n",
        "        gL=np.zeros((rows,cols))\n",
        "        currX=X[i]\n",
        "        currdelL=delL[i]\n",
        "        for j in range(rows):\n",
        "            for k in range(cols):\n",
        "                #TODO: Calculate the gradient using currX and currdelL\n",
        "                gL[j,k]= currX[j] * currdelL[k] # Fill in here\n",
        "        g.append(gL)\n",
        "    return g\n",
        "\n",
        "def updateWeights(weights,g,alpha):\n",
        "    #Enter implementation here\n",
        "    nW=[]\n",
        "    for i in range(len(weights)):\n",
        "        rows, cols = weights[i].shape\n",
        "        currWeight=weights[i]\n",
        "        currG=g[i]\n",
        "        for j in range(rows):\n",
        "            for k in range(cols):\n",
        "                #TODO: Gradient Descent Update\n",
        "                currWeight[j,k]= currWeight[j, k] - alpha * currG[j, k]\n",
        "        nW.append(currWeight)\n",
        "    return nW\n",
        "\n",
        "def activation(s):\n",
        "    #Enter implementation here\n",
        "    '''\n",
        "    - Inputs: s\n",
        "      The input to this function is a single-dimensional real-valued number. You will implement the ReLU function here.\n",
        "    – Output: x\n",
        "      The output will be the single-dimensional output of performing a ReLU operation on the inputs (i.e. x = θ(s) = ReLU (s)).\n",
        "    '''\n",
        "    x = np.where(s > 0, s, 0)\n",
        "    return x\n",
        "\n",
        "def derivativeActivation(s):\n",
        "    #Enter implementation here\n",
        "\n",
        "    '''\n",
        "    -  Inputs: s\n",
        "        The input to this function is a single-dimensional real-valued number. You will implement the derivative of the activation function (i.e. relu function) here.\n",
        "    – Output: θ′(s)\n",
        "        The output of this function is the derivative of the activation function θ(s).\n",
        "    '''\n",
        "    if s > 0:\n",
        "      theta = 1\n",
        "    else:\n",
        "      theta = 0\n",
        "    return theta\n",
        "\n",
        "def outputf(s):\n",
        "    #Enter implementation here\n",
        "    '''\n",
        "    – Inputs: s\n",
        "      The input to this function is a single-dimensional real-valued number. You will implement the output function which is the logistic regression (i.e. sigmoid) function (i.e. 1 /1 + e^(s))\n",
        "    – Output: x_L\n",
        "        The output of this function is x L which is evaluated using the logistic regression function. This is a single-dimensional value.\n",
        "    '''\n",
        "    x_L = 1 / (1 + np.exp(-s))\n",
        "\n",
        "    return x_L\n",
        "\n",
        "\n",
        "def derivativeOutput(s):\n",
        "    #Enter implementation here\n",
        "    '''\n",
        "    – Inputs: s\n",
        "      The input to this function is a single-dimensional real-valued number. You will implement the\n",
        "      derivative of the output function (i.e. sigmoid function).\n",
        "    – Output: x L\n",
        "      The output of this function is derivative of the output function evaluated at s (i.e. derivative\n",
        "      of the sigmoid function).\n",
        "    '''\n",
        "    x_L = np.exp(-s) / ( (1 + np.exp(-s))**2)\n",
        "\n",
        "    return x_L\n",
        "\n",
        "def errorf(x_L,y):\n",
        "    #Enter implementation here\n",
        "    '''\n",
        "    – Inputs: x L and y\n",
        "      The input to this function is a single-dimensional real-valued number which is x L and a single\n",
        "      dimensional discrete variable y which takes values in the set {+1,-1}. y is essentially the\n",
        "      class that the training data point xn belongs to. x L is the output from the NN model which\n",
        "      is obtained by applying forward propagation to xn. You will implement the log loss error\n",
        "      function that evaluates the error introduced in the output of the NN with respect to the training\n",
        "      observation.\n",
        "    – Output: en\n",
        "      The output of this function is en which is evaluated via the log loss error function: en(x L, y) =−Iy =+1log(x L) − Iy=−1log(1 − x L). The indicator function is denoted as Icondition which\n",
        "      returns 1 if the condition in the subscript is true and 0 otherwise.\n",
        "    '''\n",
        "    if y == 1:\n",
        "      e_n = -np.log(x_L)\n",
        "    else:\n",
        "      e_n = -np.log(1 - x_L)\n",
        "    return e_n\n",
        "\n",
        "def derivativeError(x_L,y):\n",
        "    #Enter implementation here\n",
        "    '''\n",
        "    – Inputs: x L and y\n",
        "      The input to this function is a single-dimensional real-valued number which is x L and a single\n",
        "      dimensional discrete variable y which takes values in the set {+1,-1}. y is essentially the class\n",
        "      that the training data point xn belongs to. x L is the output from the NN model which is\n",
        "      obtained by applying forward propagation to xn. You will implement the derivative of the error\n",
        "      function (i.e. log loss function) with respect to the input x L.\n",
        "    – Output: ∂en\n",
        "      The output of this function is the derivative of the error function evaluated at x L (i.e. derivative\n",
        "      of the log loss function\n",
        "    '''\n",
        "    if y == 1:\n",
        "      derivative_e_n = -1 / x_L\n",
        "    else:\n",
        "      derivative_e_n = -1 / 1 - x_L\n",
        "    return derivative_e_n\n",
        "\n",
        "def pred(x_n,weights):\n",
        "    #Enter implementation here\n",
        "    # Add a bias term in the beginning, act as an intercept\n",
        "    x_n = np.hstack([1, x_n])\n",
        "    # access the first element to get the activation of input layer\n",
        "    X = forwardPropagation(x_n, weights)[0]\n",
        "    # access the last element to get the activation of output layer, which is the final prediction\n",
        "    output = X[-1]\n",
        "    # assigning the class label based on a threshold of 0.5\n",
        "    c = +1 if output >= 0.5 else -1\n",
        "    return c\n",
        "\n",
        "\n",
        "def confMatrix(X_train,y_train,w):\n",
        "    #Enter implementation here\n",
        "     # make predictions for each data in the training set, store it in an array\n",
        "    y_pred = np.array([pred(x, w) for x in X_train])\n",
        "    # compute the confusion matrix\n",
        "    cm = confusion_matrix(y_train, y_pred)\n",
        "    return cm\n",
        "\n",
        "\n",
        "def plotErr(e,epochs):\n",
        "    #Enter implementation here\n",
        "    plt.plot(range(epochs), e)\n",
        "    plt.title('Error over epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Average Error')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def test_SciKit(X_train, X_test, Y_train, Y_test, hidden_layer_sizes):\n",
        "    #Enter implementation here\n",
        "    # initialize the built in classifier\n",
        "    classifier = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=hidden_layer_sizes, random_state=1)\n",
        "    # train NN using training dataset\n",
        "    classifier.fit(X_train, Y_train)\n",
        "    # obtain the predicted output for the testing data\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    # compute the confusion matrix\n",
        "    cm = confusion_matrix(Y_test, y_pred)\n",
        "\n",
        "    # Compute accuracy\n",
        "    y_pred_train = classifier.predict(X_train)\n",
        "    training_accuracy = accuracy_score(Y_train, y_pred_train)\n",
        "    y_pred_test = classifier.predict(X_test)\n",
        "    testing_accuracy = accuracy_score(Y_test, y_pred_test)\n",
        "\n",
        "\n",
        "    return cm, training_accuracy, testing_accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def test_Part1():\n",
        "    from sklearn.datasets import load_iris\n",
        "    X_train, y_train = load_iris(return_X_y=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_train[50:],y_train[50:],test_size=0.2, random_state=1)\n",
        "\n",
        "    for i in range(80):\n",
        "        if y_train[i]==1:\n",
        "            y_train[i]=-1\n",
        "        else:\n",
        "            y_train[i]=1\n",
        "    for j in range(20):\n",
        "        if y_test[j]==1:\n",
        "            y_test[j]=-1\n",
        "        else:\n",
        "            y_test[j]=1\n",
        "\n",
        "    err,w=fit_NeuralNetwork(X_train,y_train,1e-2,[30, 10],100)\n",
        "\n",
        "    plotErr(err,100)\n",
        "\n",
        "    cM=confMatrix(X_test,y_test,w)\n",
        "    #sciKit=test_SciKit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "    print(\"Confusion Matrix is from Part 1a is: \",cM)\n",
        "    #testing 3 different hidden layer sizes\n",
        "\n",
        "    hidden_layer_sizes = [(5, 5), (10, 10), (30, 10)]\n",
        "\n",
        "    # Test for each size\n",
        "    for sizes in hidden_layer_sizes:\n",
        "      sciKit,train_accuracy, test_accuracy = test_SciKit(X_train, X_test, y_train, y_test, sizes)\n",
        "      print(\"Confusion Matrix from Part 1b is:\",sciKit, \"hidden_layer_sizes: \", sizes, \"training accuracy: \", train_accuracy, \"testing accuracy: \", test_accuracy)\n",
        "\n",
        "test_Part1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "2j456m3GOq5s",
        "outputId": "cc6f6e35-ba91-44a9-99b4-b7517cdedb4f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-28ea4932fd76>:134: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  gL[j,k]= currX[j] * currdelL[k] # Fill in here\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAHHCAYAAACRAnNyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHtElEQVR4nO3deXhU5f3+8XuyTfZ9DwkECJsIKggiKi4ogqJYqhZpRW3rhtal2IqtVexP0WpR67fVVluXFkVwoYpSF0QRlX2XfQmQjSRkT8g6z++PkJGRIJlsZyZ5v65rLpxzTs585qklt892bMYYIwAAAA/kY3UBAAAAJ0JQAQAAHougAgAAPBZBBQAAeCyCCgAA8FgEFQAA4LEIKgAAwGMRVAAAgMciqAAAAI9FUAEAC7zyyiuy2Wxas2aN1aUAHo2gAlik6RfViV4rVqywukQAsJyf1QUA3d0jjzyi9PT044737dvXgmoAwLMQVACLjR8/XsOHD3frZ+rr6+VwOBQQEHDcucrKSoWEhLS6HmOMqqurFRQU1Op7dJa2flcAno+hH8DDZWZmymaz6amnntIzzzyjPn36yG63a+vWrXr44Ydls9m0detWXXfddYqKitI555wjqTHM/PGPf3Re36tXLz3wwAOqqalxuX+vXr10+eWX66OPPtLw4cMVFBSkv//97z9Y04IFCzRs2DAFBQUpNjZWP/3pT5Wdne08/9RTT8lms2n//v3H/ezMmTMVEBCg4uJi57GVK1fq0ksvVUREhIKDgzVmzBh99dVXLj/3Q9/1REpKSnT33XcrNTVVdrtdffv21RNPPCGHw9Fs+z799NPq2bOngoKCNGbMGG3ZsuW4e3722Wc699xzFRISosjISF155ZXatm3bcddlZ2fr5z//uZKTk2W325Wenq7bbrtNtbW1LtfV1NTo3nvvVVxcnEJCQnTVVVepoKDA5Zo1a9Zo3Lhxio2NVVBQkNLT03XTTTf94HcHugp6VACLlZaWqrCw0OWYzWZTTEyMy7GXX35Z1dXVuvnmm2W32xUdHe08d/XVVysjI0OPPfaYjDGSpF/84hd69dVX9eMf/1i//vWvtXLlSs2ePVvbtm3Tu+++63LvHTt2aMqUKbrlllv0y1/+Uv379z9hva+88opuvPFGnXnmmZo9e7YOHTqkZ599Vl999ZXWr1+vyMhIXXPNNfrNb36j+fPn67777nP5+fnz5+uSSy5RVFSUpMZf/OPHj9ewYcP00EMPycfHRy+//LIuvPBCffnllxoxYoTLzzf3XZtTVVWlMWPGKDs7W7fccovS0tL09ddfa+bMmcrNzdUzzzzjcv1rr72m8vJyTZ8+XdXV1Xr22Wd14YUXavPmzUpISJAkffrppxo/frx69+6thx9+WEeOHNFzzz2n0aNHa926derVq5ckKScnRyNGjFBJSYluvvlmDRgwQNnZ2XrrrbdUVVXl0hN25513KioqSg899JAyMzP1zDPP6I477tCbb74pScrPz9cll1yiuLg43X///YqMjFRmZqbeeeedE353oEsxACzx8ssvG0nNvux2u/O6ffv2GUkmPDzc5Ofnu9zjoYceMpLMlClTXI5v2LDBSDK/+MUvXI7PmDHDSDKfffaZ81jPnj2NJPO///3vpDXX1taa+Ph4M3jwYHPkyBHn8UWLFhlJ5g9/+IPz2KhRo8ywYcNcfn7VqlVGknnttdeMMcY4HA6TkZFhxo0bZxwOh/O6qqoqk56ebi6++OKTftcT+eMf/2hCQkLMzp07XY7ff//9xtfX1xw4cMAY8137BgUFmaysLOd1K1euNJLMPffc4zx22mmnmfj4eHP48GHnsY0bNxofHx9z/fXXO49df/31xsfHx6xevfq4upq+Z9P//mPHjnX57vfcc4/x9fU1JSUlxhhj3n33XSOp2XsB3QFDP4DF/vrXv+qTTz5xeS1evPi46yZPnqy4uLhm73Hrrbe6vP/www8lSffee6/L8V//+teSpA8++MDleHp6usaNG3fSWtesWaP8/HzdfvvtCgwMdB6/7LLLNGDAAJf7XnvttVq7dq327NnjPPbmm2/KbrfryiuvlCRt2LBBu3bt0nXXXafDhw+rsLBQhYWFqqys1EUXXaRly5a5DNM0911PZMGCBTr33HMVFRXlvG9hYaHGjh2rhoYGLVu2zOX6SZMmKSUlxfl+xIgRGjlypLMtc3NztWHDBt1www0uvVlDhgzRxRdf7LzO4XBo4cKFmjhxYrNzj2w2m8v7m2++2eXYueeeq4aGBuewWWRkpCRp0aJFqqura9F3B7oShn4Ai40YMaJFk2mbWxl0onP79++Xj4/PcSuHEhMTFRkZedzckR+69/fvK6nZoaEBAwZo+fLlzvdXX3217r33Xr355pt64IEHZIzRggULNH78eIWHh0uSdu3aJUmaNm3aCT+ztLTUOUzkTq27du3Spk2bThju8vPzXd5nZGQcd02/fv00f/58ST/83QcOHKiPPvpIlZWVqqioUFlZmQYPHtyiOtPS0lzeN33Xpjk8Y8aM0eTJkzVr1iw9/fTTOv/88zVp0iRdd911stvtLfoMwJsRVAAv8UOrcE507vv/9d6ae7dWcnKyzj33XM2fP18PPPCAVqxYoQMHDuiJJ55wXtPUW/Lkk0/qtNNOa/Y+oaGhrarV4XDo4osv1m9+85tmz/fr169F9+lovr6+zR43R+ff2Gw2vfXWW1qxYoXef/99ffTRR7rpppv05z//WStWrDiufYCuhqACdEE9e/aUw+HQrl27NHDgQOfxQ4cOqaSkRD179mz1faXGybcXXnihy7kdO3Ycd99rr71Wt99+u3bs2KE333xTwcHBmjhxovN8nz59JEnh4eEaO3Zsq2o6kT59+qiioqLF923q3TnWzp07nRNkj/3u37d9+3bFxsYqJCREQUFBCg8Pb3bFUFucddZZOuuss/Too4/q9ddf19SpUzVv3jz94he/aNfPATwNc1SALmjChAmSdNzKljlz5khqnFPSGsOHD1d8fLxeeOEFl2XOixcv1rZt24677+TJk+Xr66s33nhDCxYs0OWXX+6y78mwYcPUp08fPfXUU6qoqDju876/TNcd11xzjb755ht99NFHx50rKSlRfX29y7GFCxe6LLFetWqVVq5cqfHjx0uSkpKSdNppp+nVV19VSUmJ87otW7bo448/dra5j4+PJk2apPfff7/Z7fHND6xUak5xcfFxP9PU+/T9peZAV0SPCmCxxYsXa/v27ccdP/vss9W7d+9W3XPo0KGaNm2a/vGPf6ikpERjxozRqlWr9Oqrr2rSpEm64IILWnVff39/PfHEE7rxxhs1ZswYTZkyxbk8uVevXrrnnntcro+Pj9cFF1ygOXPmqLy8XNdee63LeR8fH7300ksaP368TjnlFN14441KSUlRdna2li5dqvDwcL3//vutqvW+++7Te++9p8svv1w33HCDhg0bpsrKSm3evFlvvfWWMjMzFRsb67y+b9++Ouecc3TbbbeppqZGzzzzjGJiYlyGjp588kmNHz9eo0aN0s9//nPn8uSIiAg9/PDDzusee+wxffzxxxozZoxuvvlmDRw4ULm5uVqwYIGWL1/unCDbEq+++qr+9re/6aqrrlKfPn1UXl6uF198UeHh4c5wBHRp1i46ArqvH1qeLMm8/PLLxpjvls8++eSTx92jacluQUHBcefq6urMrFmzTHp6uvH39zepqalm5syZprq62uW6nj17mssuu8yt2t98801z+umnG7vdbqKjo83UqVNdlvYe68UXXzSSTFhYmMuS5mOtX7/e/OhHPzIxMTHGbrebnj17mmuuucYsWbKkRd/1RMrLy83MmTNN3759TUBAgImNjTVnn322eeqpp0xtba0xxrV9//znP5vU1FRjt9vNueeeazZu3HjcPT/99FMzevRoExQUZMLDw83EiRPN1q1bj7tu//795vrrrzdxcXHGbreb3r17m+nTp5uamhpjzHf/+39/2fHSpUuNJLN06VJjjDHr1q0zU6ZMMWlpacZut5v4+Hhz+eWXmzVr1rS4HQBvZjPGzX5IAOhCMjMzlZ6erieffFIzZsywuhwA38McFQAA4LEIKgAAwGMRVAAAgMdijgoAAPBY9KgAAACPRVABAAAey6s3fHM4HMrJyVFYWFiLn2kCAACsZYxReXm5kpOT5ePzw30mXh1UcnJylJqaanUZAACgFQ4ePKgePXr84DVeHVTCwsIkNX7RpsfGAwAAz1ZWVqbU1FTn7/Ef4tVBpWm4Jzw8nKACAICXacm0DSbTAgAAj0VQAQAAHougAgAAPBZBBQAAeCyCCgAA8FgEFQAA4LEIKgAAwGMRVAAAgMciqAAAAI9FUAEAAB6LoAIAADwWQQUAAHgsr34oIQAA6Bh1DQ7ll9fIxyYlRQRZVgdBBQCAbsbhMCqsqFF2yRHllFQru6RKOSXVyik5oryyauWWVquwokbGSNcOT9UTPx5iWa0EFQAAupjy6jpnAMkuqVZ28RHllh5Rbkm1ckqP6FBZteoazEnv4+9rU53D0QkVnxhBBQAAL1LX4FBeabWyS44ou/iIsksaQ0hOSbUzjJTX1J/0Pj42KTE8UClRQUqODFJKZJCSIoOUFB6oxIhAJYQHKiYkQD4+tk74VidGUAEAwEMYY1RWXX80eBxR9tHhmOzipveNvSGOk3eGKDLYX8kRQUqJagwhyZGBSor47s/4MLv8fD1/TQ1BBQCATtLgMMovbxyKyTraG9IUQHKOzhepaEFvSICfjzN8NP4ZpOSIICVGBDqDSIi9a/yK7xrfAgAAD+BwGOWX1+hgcZWyiquUVdQYSBrfNw7RtGRuSFSwv5Ijg5QUEaSUyMCjvSLBjcEkKkixIXbLh2Q6C0EFAIAWalotk1VytEek+EhjICk+ooNFVcoqOaLa+h+efOrrY1NSRGNPSEpUkHoc7RFpmiuSHBGkoADfTvpGno+gAgDAMUqr6nSgqMr5yiqu0sFjAklLg0hqVLB6RAUpNbrxz5TIIPWIDlaCl8wN8RQEFQBAt1Lf4FBuabUOFlVpf1MgOVyl/UWVOnC4SmXVPzxHpGm1TI+o4MYekaOv1KhgpUYHKykikCDSjggqAIAuxRijospaHShq7Ak5WFTV+CpuDCU5JdVqOMmymbgwu9Kig5V6tEekqXekR1SwEiMCFeBHEOksBBUAgNcxxqigokaZhVXaV1ihzMNV2n+4UvsPV2n/4aqTrpwJ8PVRSlSQ0qKD1TMmWGnRweoVE6K0mMZQwhwRz0FQAQB4JIfDKK+sWpmHK48OzXw3RJNZePIwkhgeqNTo73pEUqMbA0lqdJASwgK7zaoZb2dpUHn44Yc1a9Ysl2P9+/fX9u3bLaoIANCZHA6j3LJqZRZWal9hpfYfrtS+wqO9I0VVPzhx1WaTekQFqVdMiNJjQ9QzJkQ9o4PVKzZYPaKCFehPr0hXYHmPyimnnKJPP/3U+d7Pz/KSAADtqGmYZl9BpTIPV2pvYaUyCxt7RTIPV6rmB8KIn4/N2RPSNESTFh2s3nEhSo0Olt2PMNLVWZ4K/Pz8lJiYaHUZAIA2Kq2q077DjSGkKYzsO/r6oWEaf9/GMJIeE6JesUdfMY1zRlhBA8uDyq5du5ScnKzAwECNGjVKs2fPVlpamtVlAQCaUd/g0MHiI9qTX6G9hRXak1+pPQUV2ltYqaLK2hP+nI9NSokKUnpsqHo3BZHYEPWODVVyJGEEJ2ZpUBk5cqReeeUV9e/fX7m5uZo1a5bOPfdcbdmyRWFhYcddX1NTo5qaGuf7srKyziwXALqN0iN12p1foT35FdpTUKE9BZXaW1ihA4erVP8DS3sTwu3OOSO940KUHhuq9NgQpUYHMUyDVrEZY1rwDMbOUVJSop49e2rOnDn6+c9/ftz55ibfSlJpaanCw8M7o0QA6DKaekeOHarZW1ih3fkVOlRWc8Kfs/v5qHdcqPrEhahPXKj6xjeGkfTYkC7zIDx0rLKyMkVERLTo97dH/RsVGRmpfv36affu3c2enzlzpu69917n+7KyMqWmpnZWeQDglRocRgeLqrTzUPnRV4V2HirX3oJK1TaceCJrYnigMhJC1Scu9GjvSIh6x4UqKZylveg8HhVUKioqtGfPHv3sZz9r9rzdbpfdbu/kqgDAOxhjlFtarR155dqWV6ZdRwPJ7vyKE66sCfT3cQ7VpB+dyNo3vrGXJDzQv5O/AXA8S4PKjBkzNHHiRPXs2VM5OTl66KGH5OvrqylTplhZFgB4tAaHUU7JEe0uqNDegsbJrLsPVWh7XtkJn1Nj9/NRn7hQ9U8MU7+EMPVLCFW/hDClRAbROwKPZmlQycrK0pQpU3T48GHFxcXpnHPO0YoVKxQXF2dlWQDgEYwxyio+om25ZdqVX6FdR4dt9hScuIfE18em3rEhGpAUrv4JocpIaAwmadHB8iWQwAtZGlTmzZtn5ccDgMeormvQrqO9Iltzy/RtTpm25Zap/AQ9JAG+PuoVG+ycP9I7NlQDksLUNz6U1TXoUjxqjgoAdHUOx9Fekrwybc8t1/a8Mu3IK1fm4Uo1t+rX39emvvFhLr0jGfGhSqWHBN0EQQUAOkhZdZ125JVre26Zth39c0deuSprG5q9PirYX/0TwzQoKUKDksM1KClcfeNDFeDHZmjovggqANAOiiprtTm7VFuyS7U5q1RbckqVVXyk2WsDfH2UkRCqAYnhGpAYpv6JYRqQGKa4MLtsNnpJgGMRVADADTX1jXNJth3tHdlxdG+SE22QlhwRqAFJ3wWSQUnh6hUbIn+2jAdahKACACdQWVOvnYfKtS23XJuzS7U5u0Q78spV19D8ht7psSEanBKhU1PCNTglQqckRSgimL1IgLYgqACAGp9ts/5AsdYdKHH2lhwoqmr22shgfw1MDHcO2fRLbJzgGsYGaUC7I6gA6HZq6x3aeaixl2TjwRKt3V+sXfkVzV4bF2bXgMSwoz0lja8eUUHMJQE6CUEFQJfW4DDaW1ChDQdLtDGrRJuzSrUtr1y1zWyY1jMmWGekRenUlAjnnJKYUB7bAViJoAKgS8kvr9aGAyVaf7BEGw6UaHN2qSpqjt80LTzQT6f2iNCpKZE6Iy1SZ/SMUiyhBPA4BBUAXqu6rkHf5pRqw8FSbThYovUHiptdEhwc4KvBKREa2iNCQ3pEakiPCKVFBzN8A3gBggoAr1DX0DivZEt2qTZmlWpTVom255ar/nvbudpsUv+EMJ2eFqnTUiN1WmqU+saHsosr4KUIKgA8UkF5jdbuL9LqzGKt3V+srbllzc4riQ21Hw0kETo9LUpDekSw+gboQggqACzncBjtLazQ2v3FWpNZrDX7i7WvsPK468IC/RpX3vSI0JCUSJ2WFqnkiECGcIAujKACoNM5HEbb8sr01e5CrdhbpHUHilVSVedyTdMQzvBeURreM1qnpUYqLTpYPgzhAN0KQQVAhzPGaE9BhVbtK9ZXewr1zZ7DKqqsdbnG7uejoamRGt4zSsN6NoYTdnUFQFAB0O5q6x36NqdUqzMb55isySxS8fd6TIIDfHVW7xid3SdGZ/aK1sCkcJ4SDOA4BBUAbVZVW+8MJKszi7ThYImq61wnvtr9fHRaaqRG9o7RuRmxGtojkmAC4KQIKgDc1uAw2pJdquW7C/XlrgKt21+i2gbXYBIV7K9hPaM1Ij1Kw3tFa3ByBMEEgNsIKgBOqq7BoS3ZpVq1r0gr9zX2mpRXu+72mhIZpJG9o3Vmr2id2StKvWNDmfgKoM0IKgCOY4zR3sJKfbmzQF/uKtQ3ew+rqrbB5ZqwQD+NOjqMc05GnHrFsNMrgPZHUAEgSSo9Uqevdxdq2a4CLdtZqOwS163oI4P9dWavaI1Mj9ZZvWM0MCmc3V4BdDiCCtBNNTiMNmWV6IudBVq2s0AbDpbo2N3oA3x9NLxXlM7rF6dzM2I1MDGcoRwAnY6gAnQjxZW1WrarQEu352vZrsLj9jLpExeiczPidF6/WJ3VO0bBAfwVAcBa/C0EdGENDqONWSX6YkeBvthZoI1ZJTLH9JqEBfrp3IxYnZcRp3P7xSklMsi6YgGgGQQVoIvJLjmi5bsKtGxXob7aXXjc1vQDEsN0wYB4XdA/XqenRcrflyXDADwXQQXwcg0OozWZRVq8JU/LdhVob4Hrw/zCAv10XkacxvSL05j+cUoID7SoUgBwH0EF8EJN4eTDzbn6cEueCsprnOd8bNJpqZE6JyNO52XE6rTUSPnRawLASxFUAC9RXdegr/cU6uNvD+nTbYdUWPHdRNiwQD9dMihRFw+K16g+sYoI4mF+ALoGggrgwUqr6rR0R74+3pqnz3cUuGy61hROLhuSqHP6xrE9PYAuiaACeJi80mp9vDVPH397SCv2Hlb9MZubJIYH6pJTEnTJoESNSI8mnADo8ggqgAfIL6vWh5tztWhTrtbsL3Y51z8hTBcPStAlpyTo1JQItqkH0K0QVACLHK6o0eIteXp/Y45WZRa57G8yvGeUxp2SqIsHJahXbIh1RQKAxQgqQCcqr67Tx98e0nsbc7R8d6EajhnWOSMtUpcNSdZlpyYpMYIlxAAgEVSADlfX4NCynQV6d322Ptl6SDX1Due5wSnhumJosi4bksyusADQDIIK0AEcDqN1B4r13sYcLdqU6/JMnd5xIbpyaIomDk1S77hQC6sEAM9HUAHaiTFGm7JKtWhTjj7YlKuc0mrnudhQu64YmqyrTk/R4JRwJsQCQAsRVIA2yi09orfXZmnB2iztP1zlPB5q99PFgxI06fQUje4Tw+6wANAKBBWgFWrrHfp02yHNX3NQy3YWqGlObJC/ry4aGK/LhyTr/P5xCvT3tbZQAPByBBXADbsOlevN1Qf1zvpsl3knI9Kjdc3wVI0fnKgQO/+3AoD2wt+owElU1zXovY05mrfqgNYdKHEejw+z68fDeujq4alKZ68TAOgQBBXgBA6VVevf3+zX3JX7VVxVJ0ny9bHpwgHx+smZqRrTL455JwDQwQgqwDGMMVp/sESvfZ2pRZtync/ZSYkM0tSz0vTjYT0UH8ZmbADQWQgqgBp3jF24PltzVx7Q9rxy5/ERvaJ10zm9NHZgAr0nAGABggq6tW9zSvXvb/brvY05qqptkCQF+Pno8iFJuvHsdJ3aI8LiCgGgeyOooNupa3Do428P6ZWv92l15ndPKu4TF6KpI3vqR2ekKDI4wMIKAQBNCCroNsqq6/SfFfv12tf7lVfWuGusn49Nlw5O1M/O6qkR6dHsGAsAHoaggi6voLxG/1y+T3NX7Fd5Tb0kKTY0QNeNSNN1I3vypGIA8GAEFXRZWcVVeuGLPZq/Jku1R59YnBEfqlvG9NHEoUmy+7FrLAB4OoIKupz9hyv1t6V79Pa6LOfy4tNSI3X7+X00dmCCfHwY3gEAb0FQQZext6BCf126Rws3ZKvhaEA5p2+spl/QV2f1Zv4JAHgjggq83pbsUj3/+R59uCVX5ujDAcf0i9OvLuqrYT2jrS0OANAmBBV4rVX7ivTXpbv1xc4C57GLBsTrzosydFpqpHWFAQDaDUEFXmdTVome+N92fbX7sCTJxyZdPiRZt53fRwOTwi2uDgDQnggq8Br7Civ11Mc79MGmXElSgK+Pfjy8h245r7d6xvD0YgDoiggq8HhFlbV65tOden3lAdU7jGw26arTUnTPxf2UGh1sdXkAgA5EUIHHqmtw6N/f7Nczn+5UWXXjRm0X9I/Tby4dwBAPAHQTBBV4pM935OuPi7ZqT0GlJGlQUrgevHyQRvWJsbgyAEBnIqjAo2zPK9PsD7c7V/LEhARoxrj+umZ4qnzZqA0Auh2CCjxCbukRzfl4p95alyVjGh8WeOPoXrrzogyFB/pbXR4AwCIEFViqqrZef126Wy99uU81R5/Hc9mQJN13SX/1imUlDwB0dwQVWGbp9nz9fuEWZZcckSSN6BWtmRMG6PS0KIsrAwB4CoIKOl1+WbVmvb9VH2xu3A8lJTJIf5g4SJcMSuB5PAAAFwQVdBqHw+j1VQf0xOLtKq+pl6+PTT8/J113j81QcAD/KgIAjsdvB3SKPQUVmvn2Zq3KLJIkDU2N1GNXDdYpyREWVwYA8GQEFXSougaH/rFsr55dsku19Q4FB/jqvnH9df2oXiw3BgCclI/VBTR5/PHHZbPZdPfdd1tdCtrJttwyXfF/X+nJj3aott6hMf3i9PE95+nG0emEFABAi3hEj8rq1av197//XUOGDLG6FLQDh8Pola8z9fj/tqu23qGoYH/9YeIgTTothcmyAAC3WN6jUlFRoalTp+rFF19UVBTLUr1dfnm1bnhltR5ZtFW19Q5dNCBen9w7Rled3oOQAgBwm+VBZfr06brssss0duzYk15bU1OjsrIylxc8x5JthzT+mS+1bGeB7H4++uOVp+ilacMVG2q3ujQAgJeydOhn3rx5WrdunVavXt2i62fPnq1Zs2Z1cFVwV3Vdgx77cJte+2a/JGlAYpj+MuV09UsIs7gyAIC3s6xH5eDBg7rrrrs0d+5cBQYGtuhnZs6cqdLSUufr4MGDHVwlTmZ7Xpmu+L/lzpBy0+h0LZw+mpACAGgXNmOMseKDFy5cqKuuukq+vr7OYw0NDbLZbPLx8VFNTY3LueaUlZUpIiJCpaWlCg8P7+iScQxjjF79OlOPLW6cMBsbatdTVw/R+f3jrS4NAODh3Pn9bdnQz0UXXaTNmze7HLvxxhs1YMAA/fa3vz1pSIF1yqrrNGP+Rn289ZAk6YL+cXry6qHMRQEAtDvLgkpYWJgGDx7sciwkJEQxMTHHHYfn2JZbptv+s1aZh6sU4OujmRMG6Iaze7GiBwDQITxiHxV4h3fWZemBdzerus6hlMgg/W3qGRqaGml1WQCALsyjgsrnn39udQloRl2DQ4+8v1X/XtE4Yfa8fnF69trTFBUSYHFlAICuzqOCCjxPeXWdbp+7Tl/uKpTNJt11UYbuvDCDLfABAJ2CoIITyik5opteWa3teeUK8vfVX6acrosHJVhdFgCgGyGooFlbskt10yurlV9eo7gwu/417Uyd2iPC6rIAAN0MQQXH+XxHvm6fu05VtQ3qnxCmf914plIig6wuCwDQDRFU4OLjb/N0x+vrVdvg0LkZsfrr1DMUHuhvdVkAgG6KoAKnDzbl6q5561XvMLrs1CQ985PT5O9r+XMrAQDdGEEFkqSF67N17/wNchhp0mnJeurqofIjpAAALEZQgRasOajfvL1JxkhXD+uhxycPYfkxAMAjEFS6uX9/k6kH//utJGnqyDT98crB8iGkAAA8BEGlG3v+8z164n/bJUk3ju6lP1w+iGf2AAA8CkGlGzLGaM4nO/XcZ7slSXde2Ff3XtyPkAIA8DgElW7GGKNHFm3Vy19lSpJ+e+kA3XZ+H2uLAgDgBAgq3YgxRg+/961e/abx4YKPXHmKrh/Vy9qiAAD4AQSVbuSFL/bq1W/2y2aT/jR5iK4enmp1SQAA/CA2yugmFq7Pdk6cffCyQYQUAIBXIKh0A1/vLtR9b22UJP3inHTddE66xRUBANAyBJUubntemW7591rVNRhdNiRJD0wYaHVJAAC0GEGlC8svq9YN/1qt8pp6jegVrT9fPZTN3AAAXoWg0kXVNTg0/fV1yiurVp+4EP3j+mEK9Pe1uiwAANxCUOminli8XaszixVm99OL1w9XZHCA1SUBAOA2gkoX9MGmXL20fJ8k6cmrh6p3XKjFFQEA0DoElS5md365fnN0hc8tY3rr0sGJFlcEAEDrEVS6kMqaet36n3WqrG3QqN4xuu+S/laXBABAm7gVVOrq6nTTTTdp3759HVUPWskYo/vf2azd+RVKCLfrL1NOl58vORQA4N3c+k3m7++vt99+u6NqQRu8vuqA3t+YIz8fm/429QzFhdmtLgkAgDZz+z+5J02apIULF3ZAKWitb3NKNev9rZIan4Y8rGe0xRUBANA+3H4oYUZGhh555BF99dVXGjZsmEJCQlzO/+pXv2q34nBy5dV1uuP19aqtd2jswHj94ly2xwcAdB02Y4xx5wfS00/8i9Bms2nv3r1tLqqlysrKFBERodLSUoWHh3fa53oKY4zufGO9Fm3KVUpkkD741TnslwIA8Hju/P52u0eFibSe4/VVB7RoU678fGz6y5TTCSkAgC6nTctCjDFys0MG7WRHXvn35qVEWVwRAADtr1VB5bXXXtOpp56qoKAgBQUFaciQIfr3v//d3rXhBBwOo/vf2aTaeocuHMC8FABA1+X20M+cOXP04IMP6o477tDo0aMlScuXL9ett96qwsJC3XPPPe1eJFy9vuqA1h8oUajdT49ddapsNp6IDADomtwOKs8995yef/55XX/99c5jV1xxhU455RQ9/PDDBJUOll9WrSf+t12SNOOSfkqMCLS4IgAAOo7bQz+5ubk6++yzjzt+9tlnKzc3t12KwonNWrRV5dX1GtojQj8b1cvqcgAA6FBuB5W+fftq/vz5xx1/8803lZGR0S5FoXlLt+frg0258vWx6bEfnSpfH4Z8AABdm9tDP7NmzdK1116rZcuWOeeofPXVV1qyZEmzAQbto6q2Xr9fuEWSdNPoXjolOcLiigAA6Hhu96hMnjxZq1atUmxsrBYuXKiFCxcqNjZWq1at0lVXXdURNULSs0t2KbvkiFIig3T32H5WlwMAQKdwq0elrq5Ot9xyix588EH95z//6aia8D1ZxVX61/LGjfZmXXGKQuxud4QBAOCVeHqyF/jLkl2qazAa3TdGYwclWF0OAACdhqcne7i9BRV6e122JOnXl/S3uBoAADoXT0/2cM8u2aUGh9FFA+J1Rhrb5AMAuheenuzBduSV69Jnl8kYadGd52hwCit9AADer8OenmyM0eeff674+HgFBQW1qUic3JxPdsgYacKpiYQUAEC35NYcFWOMMjIylJWV1VH14KjNWaX66NtD8rFJ917McmQAQPfkVlDx8fFRRkaGDh8+3FH14KinPt4hSZp0Wor6xodZXA0AANZwe9XP448/rvvuu09btmzpiHogaU1mkb7YWSA/H5vuGstjCQAA3Zfbq36uv/56VVVVaejQoQoICDhurkpRUVG7FdddPffZbknS1cN7qGdMyEmuBgCg63I7qDzzzDMdUAaabMku1Rc7C+Rjk24b09fqcgAAsJTbQWXatGkdUQeO+tvnjb0pVwxNVlpMsMXVAABgrRbPUZk/f75qa2ud77OysuRwOJzvq6qq9Kc//al9q+tmdudXaPGWPEnSbefTmwIAQIuDypQpU1RSUuJ8P2jQIGVmZjrfl5eXa+bMme1ZW7fzwhd7ZIx08aAE9U9kpQ8AAC0OKt/fwNbNDW1xElnFVVq4vvGZPref38fiagAA8AxuL09Gx3hx2V7VOxqfkHw6z/QBAEASQcUjFFbUaN7qg5Kk25mbAgCAk1urfj766CNFRDQ+c8bhcGjJkiXOjd+Onb8C9/xr+T7V1Ds0NDVSZ/eJsbocAAA8hltB5ftLk2+55RaX9zabre0VdTOVNfX69zf7JUnTz+9DGwIAcIwWB5VjlyKj/XywOVflNfXqGROssQMTrC4HAACPwhwVi715dG7KtWemyseH3hQAAI5FULHQrkPlWru/WL4+Nv34jB5WlwMAgMchqFioqTflwgHxig8PtLgaAAA8D0HFIjX1DXrn6AZvPzkz1eJqAADwTAQVi3y6NV9FlbVKCLdrTL84q8sBAMAjtSqolJSU6KWXXtLMmTNVVFQkSVq3bp2ys7PbtbiubN7qA5Kkq4elys+XvAgAQHPc2kdFkjZt2qSxY8cqIiJCmZmZ+uUvf6no6Gi98847OnDggF577bWOqLNLOVhUpeW7CyVJ1wxn2AcAgBNx+z/l7733Xt1www3atWuXAgO/mwA6YcIELVu2rF2L66oWrM2SMdLovjFKiwm2uhwAADyW20Fl9erVx+1IK0kpKSnKy8tz617PP/+8hgwZovDwcIWHh2vUqFFavHixuyV5lQaH0YI1TXunpFlcDQAAns3toGK321VWVnbc8Z07dyouzr1JoT169NDjjz+utWvXas2aNbrwwgt15ZVX6ttvv3W3LK+xbFeBckurFRnsr0sGsRMtAAA/xO2gcsUVV+iRRx5RXV2dpMbn+xw4cEC//e1vNXnyZLfuNXHiRE2YMEEZGRnq16+fHn30UYWGhmrFihXuluU13t+QI0madFqKAv19La4GAADP5nZQ+fOf/6yKigrFx8fryJEjGjNmjPr27auwsDA9+uijrS6koaFB8+bNU2VlpUaNGtXsNTU1NSorK3N5eROHw+iLnQWSpHGnJFpcDQAAns/tVT8RERH65JNPtHz5cm3atEkVFRU644wzNHbs2FYVsHnzZo0aNUrV1dUKDQ3Vu+++q0GDBjV77ezZszVr1qxWfY4n2JJTqsOVtQoJ8NWwnlFWlwMAgMezGWOMlQXU1tbqwIEDKi0t1VtvvaWXXnpJX3zxRbNhpaamRjU1Nc73ZWVlSk1NVWlpqcLDwzuz7Fb5y5JdmvPJTl0yKEH/uH641eUAAGCJsrIyRUREtOj3t9s9Kn/5y1+aPW6z2RQYGKi+ffvqvPPOk69vy+ZfBAQEqG/fvpKkYcOGafXq1Xr22Wf197///bhr7Xa77Ha7uyV7jM935EuSzu8fb3ElAAB4B7eDytNPP62CggJVVVUpKqpx+KK4uFjBwcEKDQ1Vfn6+evfuraVLlyo11f3NzBwOh0uvSVdRUlWrDQdLJEnn92fLfAAAWsLtybSPPfaYzjzzTO3atUuHDx/W4cOHtXPnTo0cOVLPPvusDhw4oMTERN1zzz0nvdfMmTO1bNkyZWZmavPmzZo5c6Y+//xzTZ06tVVfxpN9uatQDiP1SwhVcmSQ1eUAAOAV3O5R+f3vf6+3335bffr0cR7r27evnnrqKU2ePFl79+7Vn/70pxYtVc7Pz9f111+v3NxcRUREaMiQIfroo4908cUXu1uWx/t8R+NqHx5ACABAy7kdVHJzc1VfX3/c8fr6eufOtMnJySovLz/pvf75z3+6+/Fe6dhlycxPAQCg5dwe+rngggt0yy23aP369c5j69ev12233aYLL7xQUuOS4/T09Par0sttzS1TYUWNggN8NbwXy5IBAGgpt4PKP//5T0VHR2vYsGHOVTjDhw9XdHS0s4ckNDRUf/7zn9u9WG/VtNrn7D6xsvuxGy0AAC3l9tBPYmKiPvnkE23fvl07d+6UJPXv31/9+/d3XnPBBRe0X4VdwHfDPsxPAQDAHW4HlSYDBgzQgAED2rOWLqn0SJ3WHSiRxERaAADc1aqgkpWVpffee08HDhxQbW2ty7k5c+a0S2FdxfJdhWpwGPWJC1FqdLDV5QAA4FXcDipLlizRFVdcod69e2v79u0aPHiwMjMzZYzRGWec0RE1ejV2owUAoPXcnkw7c+ZMzZgxQ5s3b1ZgYKDefvttHTx4UGPGjNHVV1/dETV6LWMM81MAAGgDt4PKtm3bdP3110uS/Pz8dOTIEYWGhuqRRx7RE0880e4FerM9BRXKL69RoL+PzuwVbXU5AAB4HbeDSkhIiHNeSlJSkvbs2eM8V1hY2H6VdQEbD5ZKkgYnRyjQn2XJAAC4y+05KmeddZaWL1+ugQMHasKECfr1r3+tzZs365133tFZZ53VETV6rc3ZjUFlSI9IawsBAMBLuR1U5syZo4qKCknSrFmzVFFRoTfffFMZGRms+PmeTVklkqQhPSKsLQQAAC/lVlBpaGhQVlaWhgwZIqlxGOiFF17okMK8XV2DQ9/mlEkiqAAA0FpuzVHx9fXVJZdcouLi4o6qp8vYdahCNfUOhdn91CsmxOpyAADwSm5Pph08eLD27t3bEbV0KZuzSyRJg1Mi5ONjs7YYAAC8lNtB5f/9v/+nGTNmaNGiRcrNzVVZWZnLC402Zh2dSJvKsA8AAK3l9mTaCRMmSJKuuOIK2Wzf9RQYY2Sz2dTQ0NB+1XmxzU1BJSXS2kIAAPBibgeVpUuXdkQdXUpNfYO25zGRFgCAtnI7qIwZM6Yj6uhStueWq67BKCrYXz2igqwuBwAAr+X2HBVJ+vLLL/XTn/5UZ599trKzsyVJ//73v7V8+fJ2Lc5bbTq60dupPSJdhscAAIB73A4qb7/9tsaNG6egoCCtW7dONTU1kqTS0lI99thj7V6gN9rctNFbCsM+AAC0RatW/bzwwgt68cUX5e/v7zw+evRorVu3rl2L81abmibSMj8FAIA2cTuo7NixQ+edd95xxyMiIlRSUtIeNXm1I7UN2nmoXBLP+AEAoK3cDiqJiYnavXv3cceXL1+u3r17t0tR3uzbnFI5jBQXZldCuN3qcgAA8GpuB5Vf/vKXuuuuu7Ry5UrZbDbl5ORo7ty5mjFjhm677baOqNGrNA37DO0RwURaAADayO3lyffff78cDocuuugiVVVV6bzzzpPdbteMGTN05513dkSNXmVz04ofNnoDAKDN3A4qNptNv/vd73Tfffdp9+7dqqio0KBBgxQaGtoR9XmdjU0rfphICwBAm7k99POf//xHVVVVCggI0KBBgzRixAhCylHl1XXaW1ApSTqVoAIAQJu5HVTuuecexcfH67rrrtOHH37Is32OsSW7cdv8lMggxYYykRYAgLZyO6jk5uZq3rx5stlsuuaaa5SUlKTp06fr66+/7oj6vMomhn0AAGhXbgcVPz8/XX755Zo7d67y8/P19NNPKzMzUxdccIH69OnTETV6jS05jT0qg9mRFgCAduH2ZNpjBQcHa9y4cSouLtb+/fu1bdu29qrLKx043Dg/pW88c3YAAGgPrXooYVVVlebOnasJEyYoJSVFzzzzjK666ip9++237V2fVzlYfESSeGIyAADtxO0elZ/85CdatGiRgoODdc011+jBBx/UqFGjOqI2r1JZU6+iylpJUo+oYIurAQCga3A7qPj6+mr+/PkaN26cfH19Xc5t2bJFgwcPbrfivEl2SWNvSnignyKC/E9yNQAAaAm3g8rcuXNd3peXl+uNN97QSy+9pLVr13bb5coHi6ok0ZsCAEB7atUcFUlatmyZpk2bpqSkJD311FO68MILtWLFivaszatkHZ2fkhrN/BQAANqLWz0qeXl5euWVV/TPf/5TZWVluuaaa1RTU6OFCxdq0KBBHVWjV6BHBQCA9tfiHpWJEyeqf//+2rRpk5555hnl5OToueee68javIqzR4UVPwAAtJsW96gsXrxYv/rVr3TbbbcpIyOjI2vySlkl9KgAANDeWtyjsnz5cpWXl2vYsGEaOXKk/u///k+FhYUdWZtXOVh0dA8V5qgAANBuWhxUzjrrLL344ovKzc3VLbfconnz5ik5OVkOh0OffPKJysvLO7JOj1ZWXafSI3WS6FEBAKA9ub3qJyQkRDfddJOWL1+uzZs369e//rUef/xxxcfH64orruiIGj1e9tH5KVHB/gq1t+mpBAAA4BitXp4sSf3799ef/vQnZWVl6Y033mivmrwOK34AAOgYbQoqTXx9fTVp0iS999577XE7r8MeKgAAdIx2CSrdXZbzYYT0qAAA0J4IKu3gYHHj0A97qAAA0L4IKu2AHhUAADoGQaWNjDHKck6mpUcFAID2RFBpo7Ij9SqvqZdEjwoAAO2NoNJGTfNTYkMDFBTga3E1AAB0LQSVNso6GlRS6E0BAKDdEVTaiKcmAwDQcQgqbcSKHwAAOg5BpY0OsuIHAIAOQ1Bpo++2z6dHBQCA9kZQaQNjjHMyLT0qAAC0P4JKGxRX1amytkGSlBJJUAEAoL0RVNqgqTclPsyuQH/2UAEAoL0RVNrguxU/9KYAANARCCpt0LTih4m0AAB0DIJKG9CjAgBAxyKotMFB54ofelQAAOgIBJU2+G77fIIKAAAdgaDSSuyhAgBAxyOotFJhRa2q6xyy2aSkyECrywEAoEuyNKjMnj1bZ555psLCwhQfH69JkyZpx44dVpbUYtkljcM+CWGBsvuxhwoAAB3B0qDyxRdfaPr06VqxYoU++eQT1dXV6ZJLLlFlZaWVZbVIYXmNJCk+3G5xJQAAdF1+Vn74//73P5f3r7zyiuLj47V27Vqdd955FlXVMkWVtZKk6JAAiysBAKDrsjSofF9paakkKTo6utnzNTU1qqmpcb4vKyvrlLqaU1RFUAEAoKN5zGRah8Ohu+++W6NHj9bgwYObvWb27NmKiIhwvlJTUzu5yu84e1SCCSoAAHQUjwkq06dP15YtWzRv3rwTXjNz5kyVlpY6XwcPHuzECl05g0ooQQUAgI7iEUM/d9xxhxYtWqRly5apR48eJ7zObrfLbveMyav0qAAA0PEsDSrGGN15551699139fnnnys9Pd3KctzCZFoAADqepUFl+vTpev311/Xf//5XYWFhysvLkyRFREQoKMizd3slqAAA0PEsnaPy/PPPq7S0VOeff76SkpKcrzfffNPKslqkmKACAECHs3zoxxvV1DeovKZeEkEFAICO5DGrfrxJcWWdJMnXx6bwQH+LqwEAoOsiqLRC0/yUqGB/+fjYLK4GAICui6DSCkykBQCgcxBUWqFp+/wo9lABAKBDEVRaoaii8XlDMexKCwBAhyKotEJRVeNkWnpUAADoWASVViiqPNqjwhwVAAA6FEGlFZqWJ0cRVAAA6FAElVY4fLRHhVU/AAB0LIJKKzT1qBBUAADoWASVVjjMPioAAHQKgoqbjDEqriKoAADQGQgqbio7Uq8GR+PDFAkqAAB0LIKKm5p2pQ21+8nu52txNQAAdG0EFTc17aESFcJTkwEA6GgEFTcVOVf82C2uBACAro+g4qamHpXoYHpUAADoaAQVN9GjAgBA5yGouMnZo8IcFQAAOhxBxU30qAAA0HkIKm6iRwUAgM5DUHFTURU9KgAAdBaCipvoUQEAoPMQVNxUVNH0nB96VAAA6GgEFTdU1zWosrZBkhQdzHN+AADoaAQVNzQ9NdnXx6bwID+LqwEAoOsjqLihqLIxqEQFB8hms1lcDQAAXR9BxQ1NQSUmhGEfAAA6A0HFDc4eFVb8AADQKQgqbviuR4UVPwAAdAaCihuK6VEBAKBTEVTccLiSPVQAAOhMBBU3NC1Pjg6mRwUAgM5AUHHD4aZdaUPpUQEAoDMQVNzQ1KPC8mQAADoHQcUNx274BgAAOh5BpYUcDqPiqjpJUkwoQQUAgM5AUGmhsuo6NTiMJCmSybQAAHQKgkoLNQ37hNn9ZPfztbgaAAC6B4JKC323fT7DPgAAdBaCSgsVOTd7I6gAANBZCCotRFABAKDzEVRaqKiKoAIAQGcjqLRQUQVBBQCAzkZQaSF6VAAA6HwElRZyzlFhV1oAADoNQaWFDjP0AwBApyOotFBuabUkKTEi0OJKAADoPggqLVBd16DCihpJUkpkkMXVAADQfRBUWiDvaG9KoL8Pz/kBAKATEVRaIKf0iCQpOTJINpvN4moAAOg+CCotkFPS2KOSHMGwDwAAnYmg0gK5JU09KkykBQCgMxFUWuDYoR8AANB5CCotkM3QDwAAliCotMB3Qz8EFQAAOhNB5SSMMcphjgoAAJYgqJxE2ZF6VdY2SJKSGPoBAKBTEVROomkibXRIgIICfC2uBgCA7oWgchJNwz5JPOMHAIBOR1A5iZyj2+czkRYAgM5HUDmJph4VHkYIAEDnI6icBEM/AABYh6ByErklDP0AAGAVgspJZLPZGwAAlrE0qCxbtkwTJ05UcnKybDabFi5caGU5x2lwGOWVNfWoMPQDAEBnszSoVFZWaujQofrrX/9qZRknVFBeowaHka+PTfFhBBUAADqbn5UfPn78eI0fP97KEn5Q07BPYnigfH1sFlcDAED3Y2lQcVdNTY1qamqc78vKyjr083JLecYPAABW8qrJtLNnz1ZERITzlZqa2qGfl8NEWgAALOVVQWXmzJkqLS11vg4ePNihn5dzdGkyDyMEAMAaXjX0Y7fbZbfbO+3zvtuVlqEfAACs4FU9Kp2t6cnJ9KgAAGANS3tUKioqtHv3buf7ffv2acOGDYqOjlZaWpqFlTXKYVdaAAAsZWlQWbNmjS644ALn+3vvvVeSNG3aNL3yyisWVdWouq5BRZW1knggIQAAVrE0qJx//vkyxlhZwgk1zU8JDvBVeJBXTeUBAKDLYI7KCeSWfjfsY7Ox2RsAAFYgqJwADyMEAMB6BJUTcG72FsHSZAAArEJQOYFcVvwAAGA5gsoJfLeHCj0qAABYhaByAtnOXWnpUQEAwCoElWYYYxj6AQDAAxBUmlFSVacjdQ2SpESGfgAAsAxBpRlN81NiQwMU6O9rcTUAAHRfBJVm8IwfAAA8A0GlGZU19QoJ8GXFDwAAFuMhNs2YdHqKrjwtWbUNDqtLAQCgW6NH5QRsNpvsfsxPAQDASgQVAADgsQgqAADAYxFUAACAxyKoAAAAj0VQAQAAHougAgAAPBZBBQAAeCyCCgAA8FgEFQAA4LEIKgAAwGMRVAAAgMciqAAAAI9FUAEAAB7Lz+oC2sIYI0kqKyuzuBIAANBSTb+3m36P/xCvDirl5eWSpNTUVIsrAQAA7iovL1dERMQPXmMzLYkzHsrhcCgnJ0dhYWGy2Wzteu+ysjKlpqbq4MGDCg8Pb9d7wxVt3Xlo685DW3ce2rrztFdbG2NUXl6u5ORk+fj88CwUr+5R8fHxUY8ePTr0M8LDw/kXv5PQ1p2Htu48tHXnoa07T3u09cl6UpowmRYAAHgsggoAAPBYBJUTsNvteuihh2S3260upcujrTsPbd15aOvOQ1t3Hiva2qsn0wIAgK6NHhUAAOCxCCoAAMBjEVQAAIDHIqgAAACPRVBpxl//+lf16tVLgYGBGjlypFatWmV1SV5v9uzZOvPMMxUWFqb4+HhNmjRJO3bscLmmurpa06dPV0xMjEJDQzV58mQdOnTIooq7jscff1w2m01333238xht3X6ys7P105/+VDExMQoKCtKpp56qNWvWOM8bY/SHP/xBSUlJCgoK0tixY7Vr1y4LK/ZODQ0NevDBB5Wenq6goCD16dNHf/zjH12eFUNbt96yZcs0ceJEJScny2azaeHChS7nW9K2RUVFmjp1qsLDwxUZGamf//znqqioaHtxBi7mzZtnAgICzL/+9S/z7bffml/+8pcmMjLSHDp0yOrSvNq4cePMyy+/bLZs2WI2bNhgJkyYYNLS0kxFRYXzmltvvdWkpqaaJUuWmDVr1pizzjrLnH322RZW7f1WrVplevXqZYYMGWLuuusu53Haun0UFRWZnj17mhtuuMGsXLnS7N2713z00Udm9+7dzmsef/xxExERYRYuXGg2btxorrjiCpOenm6OHDliYeXe59FHHzUxMTFm0aJFZt++fWbBggUmNDTUPPvss85raOvW+/DDD83vfvc788477xhJ5t1333U535K2vfTSS83QoUPNihUrzJdffmn69u1rpkyZ0ubaCCrfM2LECDN9+nTn+4aGBpOcnGxmz55tYVVdT35+vpFkvvjiC2OMMSUlJcbf398sWLDAec22bduMJPPNN99YVaZXKy8vNxkZGeaTTz4xY8aMcQYV2rr9/Pa3vzXnnHPOCc87HA6TmJhonnzySeexkpISY7fbzRtvvNEZJXYZl112mbnppptcjv3oRz8yU6dONcbQ1u3p+0GlJW27detWI8msXr3aec3ixYuNzWYz2dnZbaqHoZ9j1NbWau3atRo7dqzzmI+Pj8aOHatvvvnGwsq6ntLSUklSdHS0JGnt2rWqq6tzafsBAwYoLS2Ntm+l6dOn67LLLnNpU4m2bk/vvfeehg8frquvvlrx8fE6/fTT9eKLLzrP79u3T3l5eS5tHRERoZEjR9LWbjr77LO1ZMkS7dy5U5K0ceNGLV++XOPHj5dEW3eklrTtN998o8jISA0fPtx5zdixY+Xj46OVK1e26fO9+qGE7a2wsFANDQ1KSEhwOZ6QkKDt27dbVFXX43A4dPfdd2v06NEaPHiwJCkvL08BAQGKjIx0uTYhIUF5eXkWVOnd5s2bp3Xr1mn16tXHnaOt28/evXv1/PPP695779UDDzyg1atX61e/+pUCAgI0bdo0Z3s293cKbe2e+++/X2VlZRowYIB8fX3V0NCgRx99VFOnTpUk2roDtaRt8/LyFB8f73Lez89P0dHRbW5/ggo63fTp07VlyxYtX77c6lK6pIMHD+quu+7SJ598osDAQKvL6dIcDoeGDx+uxx57TJJ0+umna8uWLXrhhRc0bdo0i6vrWubPn6+5c+fq9ddf1ymnnKINGzbo7rvvVnJyMm3dxTH0c4zY2Fj5+voet/rh0KFDSkxMtKiqruWOO+7QokWLtHTpUvXo0cN5PDExUbW1tSopKXG5nrZ339q1a5Wfn68zzjhDfn5+8vPz0xdffKG//OUv8vPzU0JCAm3dTpKSkjRo0CCXYwMHDtSBAwckydme/J3Sdvfdd5/uv/9+/eQnP9Gpp56qn/3sZ7rnnns0e/ZsSbR1R2pJ2yYmJio/P9/lfH19vYqKitrc/gSVYwQEBGjYsGFasmSJ85jD4dCSJUs0atQoCyvzfsYY3XHHHXr33Xf12WefKT093eX8sGHD5O/v79L2O3bs0IEDB2h7N1100UXavHmzNmzY4HwNHz5cU6dOdf4zbd0+Ro8efdwy+507d6pnz56SpPT0dCUmJrq0dVlZmVauXElbu6mqqko+Pq6/snx9feVwOCTR1h2pJW07atQolZSUaO3atc5rPvvsMzkcDo0cObJtBbRpKm4XNG/ePGO3280rr7xitm7dam6++WYTGRlp8vLyrC7Nq912220mIiLCfP755yY3N9f5qqqqcl5z6623mrS0NPPZZ5+ZNWvWmFGjRplRo0ZZWHXXceyqH2No6/ayatUq4+fnZx599FGza9cuM3fuXBMcHGz+85//OK95/PHHTWRkpPnvf/9rNm3aZK688kqWzLbCtGnTTEpKinN58jvvvGNiY2PNb37zG+c1tHXrlZeXm/Xr15v169cbSWbOnDlm/fr1Zv/+/caYlrXtpZdeak4//XSzcuVKs3z5cpORkcHy5I7y3HPPmbS0NBMQEGBGjBhhVqxYYXVJXk9Ss6+XX37Zec2RI0fM7bffbqKiokxwcLC56qqrTG5urnVFdyHfDyq0dft5//33zeDBg43dbjcDBgww//jHP1zOOxwO8+CDD5qEhARjt9vNRRddZHbs2GFRtd6rrKzM3HXXXSYtLc0EBgaa3r17m9/97nempqbGeQ1t3XpLly5t9u/oadOmGWNa1raHDx82U6ZMMaGhoSY8PNzceOONpry8vM212Yw5Zls/AAAAD8IcFQAA4LEIKgAAwGMRVAAAgMciqAAAAI9FUAEAAB6LoAIAADwWQQUAAHgsggqALsVms2nhwoVWlwGgnRBUALSbG264QTab7bjXpZdeanVpALyUn9UFAOhaLr30Ur388ssux+x2u0XVAPB29KgAaFd2u12JiYkur6ioKEmNwzLPP/+8xo8fr6CgIPXu3VtvvfWWy89v3rxZF154oYKCghQTE6Obb75ZFRUVLtf861//0imnnCK73a6kpCTdcccdLucLCwt11VVXKTg4WBkZGXrvvfc69ksD6DAEFQCd6sEHH9TkyZO1ceNGTZ06VT/5yU+0bds2SVJlZaXGjRunqKgorV69WgsWLNCnn37qEkSef/55TZ8+XTfffLM2b96s9957T3379nX5jFmzZumaa67Rpk2bNGHCBE2dOlVFRUWd+j0BtJM2P9YQAI6aNm2a8fX1NSEhIS6vRx991BjT+BTtW2+91eVnRo4caW677TZjjDH/+Mc/TFRUlKmoqHCe/+CDD4yPj4/Jy8szxhiTnJxsfve7352wBknm97//vfN9RUWFkWQWL17cbt8TQOdhjgqAdnXBBRfo+eefdzkWHR3t/OdRo0a5nBs1apQ2bNggSdq2bZuGDh2qkJAQ5/nRo0fL4XBox44dstlsysnJ0UUXXfSDNQwZMsT5zyEhIQoPD1d+fn5rvxIACxFUALSrkJCQ44Zi2ktQUFCLrvP393d5b7PZ5HA4OqIkAB2MOSoAOtWKFSuOez9w4EBJ0sCBA7Vx40ZVVlY6z3/11Vfy8fFR//79FRYWpl69emnJkiWdWjMA69CjAqBd1dTUKC8vz+WYn5+fYmNjJUkLFizQ8OHDdc4552ju3LlatWqV/vnPf0qSpk6dqoceekjTpk3Tww8/rIKCAt1555362c9+poSEBEnSww8/rFtvvVXx8fEaP368ysvL9dVXX+nOO+/s3C8KoFMQVAC0q//9739KSkpyOda/f39t375dUuOKnHnz5un2229XUlKS3njjDQ0aNEiSFBwcrI8++kh33XWXzjzzTAUHB2vy5MmaM2eO817Tpk1TdXW1nn76ac2YMUOxsbH68Y9/3HlfEECnshljjNVFAOgebDab3n33XU2aNMnqUgB4CeaoAAAAj0VQAQAAHos5KgA6DSPNANxFjwoAAPBYBBUAAOCxCCoAAMBjEVQAAIDHIqgAAACPRVABAAAei6ACAAA8FkEFAAB4LIIKAADwWP8f8IoIilmBC7AAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix is from Part 1a is:  [[ 0  8]\n",
            " [ 0 12]]\n",
            "Confusion Matrix from Part 1b is: [[ 8  0]\n",
            " [12  0]] hidden_layer_sizes:  (5, 5) training accuracy:  0.525 testing accuracy:  0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix from Part 1b is: [[ 7  1]\n",
            " [ 0 12]] hidden_layer_sizes:  (10, 10) training accuracy:  0.9625 testing accuracy:  0.95\n",
            "Confusion Matrix from Part 1b is: [[ 7  1]\n",
            " [ 1 11]] hidden_layer_sizes:  (30, 10) training accuracy:  0.9625 testing accuracy:  0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}